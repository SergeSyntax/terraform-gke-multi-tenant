# Multi-Tenant DevOps Infrastructure Project

This project implements a multi-tenant, multi-environment Terraform structure for provisioning GKE clusters, deploying monitoring stacks, and managing secure 3-tier applications following DevOps best practices.

## ğŸ“‹ Prerequisites

### System Requirements

- **Operating System**: Ubuntu 24.04 (tested on desktop/bastion host)
- **Hardware**: Minimum 4GB RAM, 20GB free disk space
- **Network**: Internet connectivity for downloading dependencies and accessing GCP

### Required Tools

- [Terraform](https://developer.hashicorp.com/terraform/install)
- [Google Cloud Cli](https://cloud.google.com/sdk/docs/install-sdk)
- [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl-linux)
- [helm](https://helm.sh/docs/intro/install/)
- Apt packages:

```sh
sudo apt install -y git jq
```

## ğŸš€ Quick Start Guide

### Step 1: Clone the Repository

```bash
git clone https://github.com/SergeSyntax/terraform-gke-multi-tenant
cd terraform-gke-multi-tenant
```

### Step 2: Google Cloud Authentication

```bash
gcloud init
```

### Step 3: Create a bucket to use

```bash
export BUCKET_NAME="${BUCKET_NAME:-"assign-management-terraform-state"}"
gsutil mb "gs://${BUCKET_NAME}"
```

### Step 4: Enable plugins

```bash
gcloud components install gke-gcloud-auth-plugin
```

### Step 5: Configure Environment Variables

#### For Development Environment (Currently Implemented):

```bash
# Copy and edit the development environment configuration
cp terraform/envs/dev/gcp/terraform.tfvars.example terraform/envs/dev/gcp/terraform.tfvars

# Edit the variables file with your specific values
vim terraform/envs/dev/gcp/terraform.tfvars
vim terraform/envs/dev/gcp/backend.hcl
```

#### For Other Environments (Structure Available):

The project structure supports multiple environments and tenants, but currently only the **development environment** is fully implemented:

**Available Structure:**

- `terraform/envs/dev/gcp/` - **âœ… Implemented** (Ready to use)
- `terraform/envs/dev/aws/` - **ğŸ“ Structure only** (Not implemented)
- `terraform/envs/staging/gcp/` - **ğŸ“ Structure only** (Not implemented)
- `terraform/envs/staging/aws/` - **ğŸ“ Structure only** (Not implemented)
- `terraform/envs/prod/tenant-name/` - **ğŸ“ Structure only** (Not implemented)
- `terraform/envs/prod/tenant-another-name/` - **ğŸ“ Structure only** (Not implemented)

**To implement other environments:** Copy the dev/gcp configuration and modify according to your needs:

```bash
# Example: Setting up staging environment
mkdir -p terraform/envs/staging/gcp
cp -r terraform/envs/dev/gcp/* terraform/envs/staging/gcp/
# Then modify terraform/envs/staging/gcp/terraform.tfvars for staging-specific values

# Example: Setting up production tenant
mkdir -p terraform/envs/prod/tenant-name
cp -r terraform/envs/dev/gcp/* terraform/envs/prod/tenant-name/
# Then modify terraform/envs/prod/tenant-name/terraform.tfvars for production values
```

### Step 6: Deploy Infrastructure Using Scripts

```bash
# Make scripts executable
chmod +x scripts/*.sh

# Export the bucket name
export BUCKET_NAME="${BUCKET_NAME:-"assign-management-terraform-state"}"

# Create GKE cluster (this will run terraform automatically)
./scripts/cluster.create.sh
```

**âš ï¸ CRITICAL:** After the cluster is created, you MUST run the gcloud command that the script displays to configure kubectl.

**If you missed the output or exited the terminal**, you can get and run the command again:

```bash
# Navigate to the terraform directory
cd terraform/envs/dev/gcp

# Get the cluster information from terraform outputs
project_id=$(terraform output -raw project_id)
cluster_name=$(terraform output -raw cluster_details | jq -r '.name')
cluster_location=$(terraform output -raw cluster_details | jq -r '.location')

# RUN THIS COMMAND to configure kubectl
gcloud container clusters get-credentials "${cluster_name}" --location="${cluster_location}" --project="${project_id}"
```

### Step 7: Deploy Application and Software Provisioning

**Prerequisites:** Make sure kubectl is configured (Step 6) before running this step.

```bash
# Verify kubectl context is correctly set
kubectl config current-context
kubectl get nodes

# Make k8s script executable
chmod +x scripts/k8s.apply.sh

# Deploy all Helm charts and Kubernetes manifests
./scripts/k8s.apply.sh
```

**Note:** If IP whitelisting is required for Grafana and Keycloak access, set these variables before running the script:

```bash
# Set IP ranges for service access restrictions
export KEYCLOAK_RESTRICTED_RANGE="192.115.85.127/32"
export GRAFANA_RESTRICTED_RANGE="192.115.85.127/32"

# Or use your current IP automatically
export MY_IP=$(curl -s ifconfig.me)
export KEYCLOAK_RESTRICTED_RANGE="${MY_IP}/32"
export GRAFANA_RESTRICTED_RANGE="${MY_IP}/32"

# Then run the script
./scripts/k8s.apply.sh
```

This script will deploy:

- **cert-manager** with custom values
- **ingress-nginx** (both external and internal) with custom configurations
- **kube-prometheus-stack** (Prometheus + Grafana) with monitoring values
- **keycloak** for authentication

### Step 8: Verification

```bash
# Verify GKE cluster and get service IPs
kubectl get nodes
kubectl get svc -A
```

## ğŸ§¹ Cleanup

### Destroy Infrastructure Using Scripts

```bash
# Use the automated destruction script
./scripts/cluster.destroy.sh
```

### Manual Terraform Destruction (Development Environment)

```bash
# Navigate to the development environment directory
cd terraform/envs/dev/gcp

# Destroy all resources
terraform destroy
```

**âš ï¸ Warning**: This will permanently delete all resources. Make sure you have backups if needed.

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ ansible/                              # Ansible playbooks (future automation)
â”œâ”€â”€ helm/
â”‚   â”œâ”€â”€ charts/                          # Custom Helm charts
â”‚   â””â”€â”€ values/                          # Helm values files
â”‚       â”œâ”€â”€ cert-manager.values.yml      # TLS certificate management
â”‚       â”œâ”€â”€ ingress-nginx.values.yml     # External ingress controller
â”‚       â”œâ”€â”€ internal-ingress-nginx.values.yml  # Internal ingress controller
â”‚       â”œâ”€â”€ keycloak.values.yml          # Authentication service
â”‚       â””â”€â”€ kube-prometheus-stack.values.yml   # Monitoring stack
â”œâ”€â”€ k8s/
â”‚   â”œâ”€â”€ certs/
â”‚   â”‚   â””â”€â”€ selfsgined.cluster-issuer.yml    # Self-signed certificate issuer
â”‚   â”œâ”€â”€ ingress/
â”‚   â”‚   â”œâ”€â”€ grafana.ingress.yml          # Grafana ingress configuration
â”‚   â”‚   â””â”€â”€ keycloak.ingress.yml         # Keycloak ingress configuration
â”‚   â””â”€â”€ monitoring.namespace.yml         # Monitoring namespace definition
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ k8s.apply.sh                     # Deploy all Helm charts and Kubernetes manifests
â”‚   â”œâ”€â”€ cluster.create.sh                # Create GKE cluster with Terraform
â”‚   â””â”€â”€ cluster.destroy.sh               # Destroy infrastructure
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ envs/                            # Environment-specific configurations
â”‚   â”‚   â”œâ”€â”€ dev/                         # Development environment
â”‚   â”‚   â”‚   â”œâ”€â”€ aws/                     # AWS development setup
â”‚   â”‚   â”‚   â””â”€â”€ gcp/                     # GCP development setup
â”‚   â”‚   â”‚       â”œâ”€â”€ backend.hcl          # Terraform backend configuration
â”‚   â”‚   â”‚       â”œâ”€â”€ main.tf              # Main Terraform configuration
â”‚   â”‚   â”‚       â”œâ”€â”€ outputs.tf           # Output definitions
â”‚   â”‚   â”‚       â”œâ”€â”€ providers.tf         # Provider configurations
â”‚   â”‚   â”‚       â”œâ”€â”€ terraform.tfvars     # Environment variables
â”‚   â”‚   â”‚       â”œâ”€â”€ terraform.tfvars.example  # Example configuration
â”‚   â”‚   â”‚       â””â”€â”€ variables.tf         # Variable definitions
â”‚   â”‚   â”œâ”€â”€ prod/                        # Production environment (multi-tenant)
â”‚   â”‚   â”‚   â”œâ”€â”€ tenant-another-name/     # Second production tenant
â”‚   â”‚   â”‚   â””â”€â”€ tenant-name/             # First production tenant
â”‚   â”‚   â””â”€â”€ staging/                     # Staging environment
â”‚   â”‚       â”œâ”€â”€ aws/                     # AWS staging setup
â”‚   â”‚       â””â”€â”€ gcp/                     # GCP staging setup
â”‚   â”œâ”€â”€ modules/                         # Reusable Terraform modules
â”‚   â”‚   â”œâ”€â”€ aws/                         # AWS-specific modules
â”‚   â”‚   â”‚   â”œâ”€â”€ cluster/                 # EKS cluster module
â”‚   â”‚   â”‚   â””â”€â”€ network/                 # AWS networking module
â”‚   â”‚   â””â”€â”€ gcp/                         # GCP-specific modules
â”‚   â”‚       â”œâ”€â”€ cluster/                 # GKE cluster module
â”‚   â”‚       â”œâ”€â”€ foundation/              # Basic GCP setup (projects, APIs)
â”‚   â”‚       â”œâ”€â”€ network/                 # VPC and networking
â”‚   â”‚       â””â”€â”€ postgresql/              # Cloud SQL PostgreSQL
â””â”€â”€ README.md                            # This documentation
```

## ğŸ—ï¸ Architecture Overview

### Multi-Tenant Structure

The project is designed to support multiple environments and tenants:

- **Development**: âœ… **Fully Implemented** - Single tenant for testing and development (`terraform/envs/dev/gcp/`)
- **Staging**: ğŸ“ **Structure Available** - Environment for pre-production testing (`terraform/envs/staging/`)
- **Production**: ğŸ“ **Structure Available** - Multi-tenant setup supporting multiple organizations
  - `terraform/envs/prod/tenant-name/` - Primary production tenant structure
  - `terraform/envs/prod/tenant-another-name/` - Secondary production tenant structure

### Implementation Status

| Environment              | Cloud Provider | Status       | Description                                      |
| ------------------------ | -------------- | ------------ | ------------------------------------------------ |
| **dev/gcp**              | Google Cloud   | âœ… **Ready** | Fully implemented with modules and configuration |
| dev/aws                  | AWS            | ğŸ“ Structure | Folder structure only, needs implementation      |
| staging/gcp              | Google Cloud   | ğŸ“ Structure | Copy from dev/gcp and modify                     |
| staging/aws              | AWS            | ğŸ“ Structure | Copy from dev/aws and modify                     |
| prod/tenant-name         | Multi-Cloud    | ğŸ“ Structure | Copy from dev and customize for production       |
| prod/tenant-another-name | Multi-Cloud    | ğŸ“ Structure | Copy from dev and customize for production       |

### Available Terraform Modules

Currently implemented for GCP:

- **cluster/** - âœ… GKE cluster module
- **foundation/** - âœ… Basic GCP setup (projects, APIs)
- **network/** - âœ… VPC and networking
- **postgresql/** - âœ… Cloud SQL PostgreSQL

AWS modules (structure only):

- **cluster/** - ğŸ“ EKS cluster module (not implemented)
- **network/** - ğŸ“ AWS networking module (not implemented)

### Infrastructure Components

- **GKE Clusters**: Managed Kubernetes clusters per environment/tenant
- **Networking**: Custom VPC with proper security groups and firewall rules
- **Database**: Cloud SQL PostgreSQL for persistent data
- **Monitoring**: Prometheus + Grafana stack with custom dashboards
- **Security**: TLS certificates, IP restrictions, and authentication via Keycloak
- **Ingress**: NGINX ingress controllers (external and internal routing)

## ğŸ“ Notes

- This setup is designed for demonstration purposes
- For production use, consider implementing proper secret management
- Review security configurations before deploying to production environments
- Monitor costs in GCP console during testing

---
